import streamlit as st
import pandas as pd
import numpy as np
import dill
import plotly.express as px
import matplotlib.pyplot as plt
import shap
from sklearn.model_selection import train_test_split
import pydeck as pdk

############################################################### FUN√á√ïES √öTEIS
# fun√ß√£o que calcula diferen√ßa entre max e min
def max_min_diff(x):
    return np.max(x) - np.min(x)

# Gerar texto explicativo com base nos valores SHAP
def gerar_explicacao_textual(feature_names, shap_values, baseline, probabilidade, sorted_indices):
    explicacao = []
    explicacao.append(f"O valor base (m√©dio) de log-odds √© de {baseline:.2f}, o que corresponde a uma probabilidade inicial de degrada√ß√£o igual a {sigmoid(baseline):.2%}.")
    
    base = baseline
    for i in sorted_indices:
        feature = feature_names[i]
        shap_value = shap_values[i]
        impacto = "aumentou" if shap_value > 0 else "diminuiu"
        base = base + shap_value
        explicacao.append(f"A vari√°vel '{feature}' {impacto} o log-odds em {abs(shap_value):.2f} unidades, o que fez a probabilidade se tornar {sigmoid(base):.2%}.")
    
    explicacao.append(f"Assim, a probabilidade final de que a pastagem est√° DEGRADADA √© {probabilidade:.2%}.")
    return " ".join(explicacao)

# Fun√ß√£o para converter log-odds para probabilidade
def sigmoid(x):
    return 1 / (1 + np.exp(-x))


############################################################### CARREGANDO VARI√ÅVEIS √öTEIS
    
# carregando dados de refer√™ncia
dados = pd.read_excel("dados/dados_escores_processados.xlsx")
dados_completos = dados.copy()
escores = [col for col in dados.columns if col not in ["Ponto", "PontoID", "Data", "Campo", "Equipe",
                                                       "Especie01", "Avaliador"]]
dados = dados.groupby("PontoID")[escores].agg(["mean", "min", "max", max_min_diff])
dados.columns = [col + "_" + func for col, func in zip(dados.columns.get_level_values(0), dados.columns.get_level_values(1))]

# carregando dados de classe
dados_classe = pd.read_excel("dados/dados_geoloc_classe.xlsx")
dados_classe.index = dados_classe["PontoID"]
dados_classe.drop(columns="PontoID", inplace=True)

# fazendo inner join entre tabelas (incluindo apenas as linhas com PontoID que possui classe)
dados = dados.join(dados_classe, how="inner")

# fazendo left join entre tabelas para os dados completos
dados_completos.index = dados_completos["PontoID"]
dados_completos.drop(columns="PontoID", inplace=True)
dados_completos = dados_completos.join(dados_classe, on="PontoID", how="left", lsuffix='_left', rsuffix='_right')

# dados de entrada e sa√≠da do modelo
y = (~dados["CLASS_DED"].isin(["N√£o degradada", "Degrada√ß√£o Baixa"])*1).values
X = dados.drop(columns=["CLASS_DED"] + [col for col in dados.columns\
                                        if "min" in col\
                                            or "max" in col\
                                                or "Degrad" in col\
                                                    or "Manejo" in col])

# dados de treino e dados de teste
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.3, random_state=667)

# carregando modelo de classifica√ß√£o
with open("dados/melhor_modelo.pk", "rb") as file:
    bs_model = dill.load(file)



############################################################### O APLICATIVO WEB COME√áA AQUI
# sele√ß√£o da se√ß√£o
section = st.sidebar.selectbox("Section:", ["Predi√ß√£o da Degrada√ß√£o de Pastagens",
                                            "Mapa Tem√°tico",
                                            "An√°lise Descritiva",
                                            "An√°lise de Discord√¢ncia entre Avaliadores"])

# texto da aba
st.sidebar.markdown("""               
Bem-vindo ao nosso aplicativo web desenvolvido para o primeiro Datathon do Engope! Aqui, voc√™ encontrar√° uma solu√ß√£o interativa e visual para an√°lise de dados sobre a classifica√ß√£o de de degrada√ß√£o de pastagens. Nosso objetivo √© proporcionar uma maneira pr√°tica e eficiente de explorar essas informa√ß√µes de maneira detalhada.
Utilizamos gr√°ficos intuitivos e interativos, que facilitam a compreens√£o das caracter√≠sticas principais dos dados de pastagem. Al√©m disso, disponibilizamos um mapa interativo que apresenta a posi√ß√£o e a classifica√ß√£o das pastagens, permitindo uma visualiza√ß√£o geogr√°fica clara e objetiva.
Outro destaque √© o nosso modelo de predi√ß√£o, que prediz se a pastagem est√° degradada ou n√£o. E para garantir a consist√™ncia das an√°lises, inclu√≠mos uma breve avalia√ß√£o da concord√¢ncia entre os avaliadores, oferecendo uma vis√£o sobre a qualidade das classifica√ß√µes.
Explore nosso aplicativo e descubra como esses recursos podem facilitar o entendimento e a explora√ß√£o dos dados de pastagem!
""", unsafe_allow_html=True)

###################################### SE√á√ÉO: "Predi√ß√£o da Degrada√ß√£o de Pastagens"
if section == "Predi√ß√£o da Degrada√ß√£o de Pastagens":

    st.markdown("""
## üåæ Predi√ß√£o da Degrada√ß√£o de Pastagens

O modelo de classifica√ß√£o utilizado foi o XGBoost, cujos hiperpar√¢metros foram otimizados usando o otimizador de Bayes e valida√ß√£o cruzada.
O modelo foi treinado para separar as pastagens entre a **classe positiva** (**DEGRADADA**: excluindo a classe Degrada√ß√£o Baixa) e a **classe negativa** (**N√ÉO DEGRADADA**: que agrupa as classes Degrada√ß√£o Baixa e N√£o degradada).

Como dados de entrada do modelo, foram utilizados os escores m√©dios entre os avaliadores respons√°veis pela pastagem. Foram exclu√≠dos os escores "Degrad" e "Manejo" por terem rela√ß√£o muito direta com a classe positiva ou negativa.

A performance do modelo nos dados de teste (30\% do total de pontos: 138 inst√¢ncias) foi:

- Classe pastagem 'DEGRADADA': Precis√£o = 100\%, Sensibilidade = 98.91\%, F1-score = 99.45\%
- Classe pastagem 'N√ÉO DEGRADADA': Precis√£o = 97.87\%, Sensibilidade = 100.00\%, F1-score = 98.92\%

Para testar as predi√ß√µes do modelo, voc√™ pode preencher o formul√°rio abaixo e clicar em "Predizer". Ap√≥s o clique, aparecer√° o resultado da predi√ß√£o e a explica√ß√£o da contribui√ß√£o de cada vari√°vel para a probabilidade final da classe positiva. A explica√ß√£o √© baseada nos valores SHAP, provenientes da teoria dos jogos. Os valores SHAP buscam dividir a recompensa final de um "jogo" de acordo com a contribui√ß√£o dos jogadores de uma mesma equipe.
    """)

    with st.form(key = "user_input"):
        st.markdown("""
        <h3 style='text-align: center;'>Dados de entrada</h3>
        """, unsafe_allow_html=True)
        
        altura = st.slider("Altura", X["Altura_mean"].min(), X["Altura_mean"].max(), X["Altura_mean"].mean(),
                                   format="%.1f", step=0.1)
        estdesenv = st.slider("EstDesenv (m√©dia entre avaliadores)", 1.0, 7.0, X["EstDesenv_mean"].mean(),
                                   format="%.1f", step=0.1)
        invasoras = st.slider("Invasoras (m√©dia entre avaliadores)", 1.0, 7.0, X["Invasoras_mean"].mean(),
                                   format="%.1f", step=0.1)
        cupins = st.slider("Cupins (m√©dia entre avaliadores)", 1.0, 7.0, X["Cupins_mean"].mean(),
                                   format="%.1f", step=0.1)
        cobertsolo = st.slider("CobertSolo (m√©dia entre avaliadores)", 1.0, 7.0, X["CobertSolo_mean"].mean(),
                                   format="%.1f", step=0.1)
        dispforr = st.slider("DispForr (m√©dia entre avaliadores)", 1.0, 7.0, X["DispForr_mean"].mean(),
                                   format="%.1f", step=0.1)
        dispfolhverd = st.slider("DispFolhVerd (m√©dia entre avaliadores)", 1.0, 7.0, X["DispFolhVerd_mean"].mean(),
                                   format="%.1f", step=0.1)
        condatual = st.slider("CondAtual (m√©dia entre avaliadores)", 1.0, 7.0, X["CondAtual_mean"].mean(),
                                   format="%.1f", step=0.1)
        potprod = st.slider("PotProd (m√©dia entre avaliadores)", 1.0, 7.0, X["PotProd_mean"].mean(),
                                   format="%.1f", step=0.1)

        predict = st.columns(5)[-1].form_submit_button("Predizer")

    if predict:
        # inicializando dados do usu√°rio
        X_user = {}

        # inputs num√©ricos
        X_user["Altura_mean"] = [altura]
        X_user["EstDesenv_mean"] = [estdesenv]
        X_user["Invasoras_mean"] = [invasoras]
        X_user["Cupins_mean"] = [cupins]
        X_user["CobertSolo_mean"] = [cobertsolo]
        X_user["DispForr_mean"] = [dispforr]
        X_user["DispFolhVerd_mean"] = [dispfolhverd]
        X_user["CondAtual_mean"] = [condatual]
        X_user["PotProd_mean"] = [potprod]

        # convertendo dados do usu√°rio para um DataFrame
        X_user = pd.DataFrame(X_user)
        
        # predizendo
        y_pred = bs_model.predict(X_user)

        if y_pred[0] == 1:
            success_text = f"A pastagem com os scores fornecidos foi predita como: DEGRADADA"
        else:
            success_text = f"A pastagem com os scores fornecidos foi predita como: N√ÉO DEGRADADA"

        # printando y_pred
        st.success(success_text, icon="ü¶â")

        # "explainer" do pacote shap (espec√≠fico para √°rvores de decis√£o)
        shap_model = shap.TreeExplainer(bs_model.best_estimator_)

        # obtendo valores shap
        shap_values = shap_model.shap_values(X_user)

        # converter os shap_values para um objeto Explanation
        explainer = shap.Explanation(values=shap_values[0], base_values=shap_model.expected_value, data=X_user.iloc[0,:])

        # Calcular o valor logit final (soma do baseline com as contribui√ß√µes das features)
        logit_value = explainer.base_values + sum(explainer.values)

        # Converter para probabilidade final
        probabilidade = sigmoid(logit_value)

        # gerar o waterfall_plot
        waterfall_plot = shap.waterfall_plot(explainer)

        # salvar o gr√°fico como uma imagem
        plt.gcf().set_size_inches(8, 6)
        plt.tight_layout()
        plt.savefig("shap_waterfall_plot.png")

        # Ordenar os √≠ndices dos valores SHAP por magnitude (impacto)
        sorted_indices = np.argsort(np.abs(shap_values[0]))

        # gerando texto explicativo junto ao plot
        st.markdown(f"""
        <h4 style='text-align: center;'>üïµÔ∏è Interpretando a predi√ß√£o (valores SHAP)</h4>
        
        {gerar_explicacao_textual(X_user.columns, shap_values[0], explainer.base_values, probabilidade, sorted_indices)}""", unsafe_allow_html=True)

        # mostrando imagem salva
        st.image("shap_waterfall_plot.png")

###################################### SE√á√ÉO: "Mapa Tem√°tico"
elif section == "Mapa Tem√°tico":

    y_pred = bs_model.predict(dados[[escore + "_mean" for escore in escores if "Degrad" not in escore and "Manejo" not in escore]])#DC0D2F
    dados["y_pred"] = y_pred
    dados["y_pred_class"] = dados["y_pred"].map({1: "DEGRADADA", 0: "N√ÉO DEGRADADA"})
    dados["color"] = dados["y_pred"].map({1: [255, 0, 0], 0: [0, 255, 0]})

    st.markdown(f"""
        <h4 style='text-align: center;'>üó∫Ô∏è Mapa tem√°tico das predi√ß√µes do modelo</h4>
        
        O mapa tem√°tico mostrando a posi√ß√£o, identifica√ß√£o e o estado de degrada√ß√£o das pastagens conforme predito pelo modelo de classifica√ß√£o treinado est√° mostrado logo abaixo.""", unsafe_allow_html=True)

    # Crie um Layer de Scatterplot usando pydeck
    layer = pdk.Layer(
        'ScatterplotLayer',
        dados,
        get_position='[LON, LAT]',
        get_color='color',
        get_radius=1000,
        pickable=True,
    )

    # Configura√ß√µes da visualiza√ß√£o
    view_state = pdk.ViewState(
        latitude=dados['LAT'].mean(),
        longitude=dados['LON'].mean(),
        zoom=5.5,
        pitch=0,
    )

    # Renderize o mapa com pydeck
    st.pydeck_chart(pdk.Deck(
        layers=[layer],
        initial_view_state=view_state,
        tooltip={"html": "<b>ID:</b> {Ponto} <br/> <b>Predi√ß√£o:</b> {y_pred_class}"}
    ))


###################################### SE√á√ÉO: "An√°lise Descritiva"
elif section == "An√°lise Descritiva":

    st.markdown(f"""
        <h3 style='text-align: center;'>üìä An√°lise Descritiva das vari√°veis</h3>
        
        <h4 style='text-align: center;'>Boxplot dos scores agrupados por classe de pastagem</h4>
                
        Note que, para o eixo x, a vari√°vel `CLASS_DED` corresponde √†s classes presentes em `dados_geoloc_classe.xlsx`, enquanto que
                a vari√°vel `y_pred_class` corresponde √†s predi√ß√µes do modelo de classifica√ß√£o treinado.""", unsafe_allow_html=True)


    y_pred = bs_model.predict(dados[[escore + "_mean" for escore in escores if "Degrad" not in escore and "Manejo" not in escore]])#DC0D2F
    dados["y_pred"] = y_pred
    dados["y_pred_class"] = dados["y_pred"].map({1: "DEGRADADA", 0: "N√ÉO DEGRADADA"})

    # y_col = st.selectbox("Vari√°vel do eixo y:", [escore + "_mean" for escore in escores] +\
    #                                             [escore + "_min" for escore in escores] +\
    #                                             [escore + "_max" for escore in escores] +\
    #                                             [escore + "_max_min_diff" for escore in escores])
    y_col = st.selectbox("Vari√°vel do eixo y:", [escore + "_mean" for escore in escores])
    x_col = st.selectbox("Vari√°vel do eixo x:", ["CLASS_DED", "y_pred_class"])
    fig = px.box(dados, x=x_col, y=y_col, points="all")
    st.plotly_chart(fig)


    st.markdown(f"""
        
        <h4 style='text-align: center;'>Scatterplot dos scores coloridos por classe de pastagem</h4>
                
        Note que, para a cor, a vari√°vel `CLASS_DED` corresponde √†s classes presentes em `dados_geoloc_classe.xlsx`, enquanto que
                a vari√°vel `y_pred_class` corresponde √†s predi√ß√µes do modelo de classifica√ß√£o treinado.""", unsafe_allow_html=True)
    y_col = st.selectbox(" Vari√°vel do eixo y:", [escore + "_mean" for escore in escores])
    x_col = st.selectbox(" Vari√°vel do eixo x:", [escore + "_mean" for escore in escores[::-1]])
    color_col = st.selectbox("Vari√°vel para a cor:", ["CLASS_DED", "y_pred_class"])
    fig = px.scatter(dados, x=x_col, y=y_col, color=color_col)
    st.plotly_chart(fig)


###################################### SE√á√ÉO: "An√°lise de Discord√¢ncia entre Avaliadores"
elif section == "An√°lise de Discord√¢ncia entre Avaliadores":

    st.markdown(f"""
        <h3 style='text-align: center;'>üìä An√°lise de Discord√¢ncia entre Avaliadores</h3>
        
        <h4 style='text-align: center;'>Boxplot da diferen√ßa entre o escores m√°ximo e m√≠nimo para diferentes m√©tricas</h4>""", unsafe_allow_html=True)


    y_pred = bs_model.predict(dados[[escore + "_mean" for escore in escores if "Degrad" not in escore and "Manejo" not in escore]])
    dados["y_pred"] = y_pred
    dados["y_pred_class"] = dados["y_pred"].map({1: "DEGRADADA", 0: "N√ÉO DEGRADADA"})

    dados_temp = dados[dados["DispFolhVerd_max_min_diff"] <= 6].melt(id_vars=["Ponto", "y_pred_class", "CLASS_DED"], value_vars=[escore + "_max_min_diff" for escore in escores])

    fig = px.box(dados_temp, x="variable", y="value")
    st.plotly_chart(fig)


    st.markdown(f"""
        <h4 style='text-align: center;'>Boxplot da diferen√ßa entre o escores m√°ximo e m√≠nimo para um escore considerando as diferentes classes de pastagem</h4>""", unsafe_allow_html=True)
    y_col = st.selectbox("Vari√°vel do eixo y:", [escore + "_max_min_diff" for escore in escores])
    x_col = st.selectbox("Vari√°vel do eixo x:", ["CLASS_DED", "y_pred_class"])
    fig = px.box(dados, x=x_col, y=y_col)
    st.plotly_chart(fig)